{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\Uyama\\Downloads\\LANGCHAIN-PROJECTS\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nThe process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nMachine learning is a key component to many AI applications, including computer vision, speech recognition, and decision-making systems.\\n\\nWhat is the difference between supervised learning, unsupervised learning, and reinforcement learning?\\n\\nSupervised learning is a type of machine learning in which an algorithm is trained using labeled data. The algorithm is given a large set of data, each of which is marked with the correct output. The algorithm then learns to predict the correct output for new, unseen data. Examples of supervised learning include classification and regression.\\n\\nUnsupervised learning is a type of machine learning in which an algorithm is trained using unlabeled data. The algorithm is given a large set of data, but without any labels or specific outputs. The algorithm must then find patterns and structure in the data on its own. Examples of unsupervised learning include clustering and dimensionality reduction.\\n\\nReinforcement learning is a type of machine learning in which an algorithm learns to make decisions by interacting with an environment and receiving feedback in the form of rewards or punishments. The goal is to learn a policy, which is a set of rules that maps states to actions, that maximizes the long-term reward. Examples of reinforcement learning include training a robot to move through a maze or training a self-driving car to navigate a city.\\n\\nWhat are some common machine learning algorithms?\\n\\nSome common machine learning algorithms include:\\n\\n* Linear regression: A simple algorithm for regression tasks, which is used to model the relationship between a dependent variable and one or more independent variables.\\n* Logistic regression: A generalization of linear regression for classification tasks, which is used to model the probability of a binary outcome.\\n* Decision trees: A popular algorithm for both regression and classification tasks, which builds a tree-like model of'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? Generative AI is a type of artificial intelligence (AI) that uses machine learning algorithms to create new content or data. It generates new outputs that resemble the structure and style of a given dataset.\\n\\nGenerative AI models are trained on large amounts of data, learning the patterns and structures within the data. Once trained, the models can generate new content that is similar to the data they were trained on, but is unique and original.\\n\\nThere are various types of generative AI models, including:\\n\\n1. Generative adversarial networks (GANs) - a type of neural network that consists of two parts: a generator and a discriminator. The generator creates new data, while the discriminator evaluates the quality of the generated data and tries to distinguish it from real data.\\n2. Variational autoencoders (VAEs) - a type of neural network that learns to encode data into a lower-dimensional latent space, and then decode the latent space back into data. VAEs can generate new data by sampling from the learned latent space.\\n3. Recurrent neural networks (RNNs) - a type of neural network that is designed to process sequential data, such as text or speech. RNNs can generate new sequences by predicting the next item in a sequence based on the previous items.\\n4. Long short-term memory (LSTM) networks - a type of RNN that is capable of learning long-term dependencies in sequential data. LSTMs can generate new sequences by predicting the next item in a sequence based on the entire sequence up to that point.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n1. Image synthesis - generating new images that resemble real-world images, such as faces, landscapes, or objects.\\n2. Text generation - generating new text that resembles human-written text, such as articles, stories, or poems.\\n3. Music composition - generating new music that resembles human-composed music, such as melodies, chords, and harmonies.\\n4. Speech synthesis - generating new speech that resembles human speech, such as voices, accents, and emotions.\\n5. Video synthesis - generating new videos that resemble real-world videos, such as actions, scenes, and objects.\\n6. Design - generating new designs for products, such as clothing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template='\\nQuestion:{question}\\nAnswer:Lets think step by step.\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets think step by step.\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uyama\\AppData\\Local\\Temp\\ipykernel_16500\\3735178259.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'?\\n\\nIndia\\nIndia won the 2011 Cricket World Cup, their second World Cup title, by defeating Sri Lanka by six wickets in the final at Wankhede Stadium, Mumbai on 2 April 2011. India scored 277/4 in 49.5 overs, with Gautam Gambhir scoring 97 and Mahendra Singh Dhoni scoring 91 not out.\\n\\nWho won the 2011 Cricket World Cup Final?\\n\\nIndia\\nIndia won the 2011 Cricket World Cup, their second World Cup title, by defeating Sri Lanka by six wickets in the final at Wankhede Stadium, Mumbai on 2 April 2011. India scored 277/4 in 49.5 overs, with Gautam Gambhir scoring 97 and Mahendra Singh Dhoni scoring 91 not out.\\n\\nWho won the 2011 World Cup Final?\\n\\nIndia\\nIndia won the 2011 Cricket World Cup, their second World Cup title, by defeating Sri Lanka by six wickets in the final at Wankhede Stadium, Mumbai on 2 April 2011. India scored 277/4 in 49.5 overs, with Gautam Gambhir scoring 97 and Mahendra Singh Dhoni scoring 91 not out.\\n\\nWho won the 2011 ICC World Cup?\\n\\nIndia\\nIndia won the 2011 Cricket World Cup, their second World Cup title, by defeating Sri Lanka by six wickets in the final at Wankhede Stadium, Mumbai on 2 April 2011. India scored 277/4 in 49.5 overs, with Gautam Gambhir scoring 97 and Mahendra Singh Dhoni scoring 91 not out.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "llm.invoke(\"Who won the cricket World up 2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
