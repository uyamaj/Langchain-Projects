{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I want you to act as a finanacial advisor for people.\\nIn an easy way, explain the basics of income tax.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "demo_template=\"\"\" I want you to act as a finanacial advisor for people.\n",
    "In an easy way, explain the basics of {financial_concept}.\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(\n",
    "    input_variables= [\"financial_concept\"],\n",
    "    template= demo_template\n",
    "    )\n",
    "\n",
    "prompt.format(financial_concept=\"income tax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\Uyama\\Downloads\\LANGCHAIN-PROJECTS\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceEndpoint\n",
    "\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uyama\\AppData\\Local\\Temp\\ipykernel_17756\\1648945088.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "chain=LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSure! Here's a simple breakdown of the basics of income tax:\\n\\n1. **What is Income Tax?**\\nIncome tax is a levy imposed by the government on individuals and entities (like businesses) on a certain portion of their income, which is known as taxable income. The purpose of income tax is to fund public services and infrastructure.\\n\\n2. **Who Needs to Pay Income Tax?**\\nIn most countries, if you're an individual earning above a certain threshold (known as the tax-free allowance or basic personal allowance), you're required to pay income tax. For businesses, they pay taxes on their profits.\\n\\n3. **How is Taxable Income Calculated?**\\nTaxable income is calculated by subtracting allowable expenses and deductions from your total income. For individuals, common examples of deductions include mortgage interest, student loan interest, and charitable donations. For businesses, examples include business expenses and depreciation.\\n\\n4. **Income Tax Rates**\\nIncome tax rates vary depending on the jurisdiction and the amount of taxable income. In the United States, for example, there are seven federal tax brackets ranging from 10% to 37%. In the UK, there are three main rates: 20%, 40%, and 45%.\\n\\n5. **Filing a Tax Return**\\nTo pay income tax, you need to file a tax return, which is a document that summarizes your income and expenses for the tax year. The deadline for filing a tax return varies by jurisdiction, but in the U.S., it's usually April 15 (or the following business day if April 15 falls on a weekend).\\n\\n6. **Tax Deductions and Credits**\\nTo help reduce your tax liability, you can claim deductions (expenses that reduce your taxable income) and credits (direct reductions in the amount of tax you owe). Common examples include education credits, retirement savings contributions, and home energy efficiency improvements.\\n\\n7. **Tax Planning**\\nTax planning is the process of organizing your financial affairs in a way that minimizes your tax liability. This could involve strategies like maximizing your deductions and credits, deferring income, or accelerating expenses. It's a good idea to consult with\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"income tax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGDP, or Gross Domestic Product, is a measure of the total value of all goods and services produced within a country's borders during a specific period, usually a year. It's like a report card for a country, showing how well its economy is doing.\\n\\nHere's a simple breakdown:\\n\\n1. **Goods**: These are physical, tangible items like cars, houses, food, and electronics.\\n\\n2. **Services**: These are intangible items like healthcare, education, finance, and entertainment.\\n\\n3. **Produced**: The items must be produced within the country's borders. If a Japanese car company makes cars in the U.S., that contributes to U.S. GDP.\\n\\n4. **During a specific period**: Typically, this is a year. Quarterly GDP reports are also common.\\n\\n5. **Total value**: The value is the market price of the goods and services. If a car costs $20,000, and 100 cars are produced, that's $2,000,000 added to GDP.\\n\\nHigher GDP usually means a stronger economy, but it's not the only factor. It's important to consider factors like income distribution, unemployment rate, and inflation rate as well.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"GDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In an easy way translate the following sentence \"How are you\" into French\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language Translation\n",
    "\n",
    "template=\"\"\"In an easy way translate the following sentence \"{sentence}\" into {target_language}\n",
    "\"\"\"\n",
    "language_prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"target_language\"],\n",
    "    template=template,\n",
    ")\n",
    "language_prompt.format(sentence=\"How are you\", target_language=\"French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Uyama\\AppData\\Local\\Temp\\ipykernel_17756\\1390587033.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  chain2({'sentence':\"Hello How are you\",'target_language':'French'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello How are you',\n",
       " 'target_language': 'French',\n",
       " 'text': '\\nThe French translation for \"Hello How are you\" is \"Bonjour comment Ã§a va?\". This phrase is commonly used as a greeting and a way to ask about someone\\'s well-being in French-speaking countries.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=LLMChain(llm=llm,prompt=language_prompt)\n",
    "\n",
    "chain2({'sentence':\"Hello How are you\",'target_language':'French'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create the `FewShotPromptTemplate` object.\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big',\n",
       " 'text': ' small\\n\\nWord: warm\\nAntonym: cold\\n\\nWord: fast\\nAntonym: slow\\n\\nWord: light\\nAntonym: heavy\\n\\nWord: clear\\nAntonym: opaque\\n\\nWord: good\\nAntonym: bad\\n\\nWord: alive\\nAntonym: dead\\n\\nWord: rich\\nAntonym: poor\\n\\nWord: hot\\nAntonym: cool\\n\\nWord: strong\\nAntonym: weak\\n\\nWord: new\\nAntonym: old\\n\\nWord: intelligent\\nAntonym: unintelligent\\n\\nWord: easy\\nAntonym: difficult\\n\\nWord: fair\\nAntonym: unfair\\n\\nWord: polite\\nAntonym: rude\\n\\nWord: calm\\nAntonym: agitated\\n\\nWord: love\\nAntonym: hate\\n\\nWord: straight\\nAntonym: crooked\\n\\nWord: high\\nAntonym: low\\n\\nWord: loud\\nAntonym: quiet\\n\\nWord: dry\\nAntonym: wet\\n\\nWord: simple\\nAntonym: complex\\n\\nWord: fresh\\nAntonym: stale\\n\\nWord: right\\nAntonym: wrong\\n\\nWord: obedient\\nAntonym: disobedient\\n\\nWord: certain\\nAntonym: uncertain\\n\\nWord: thin\\nAntonym: fat\\n\\nWord: dark\\nAntonym: light\\n\\nWord: long\\nAntonym: short\\n\\nWord: heavy\\nAntonym: light\\n\\nWord: cold\\nAntonym: hot\\n\\nWord: small\\nAntonym: big\\n\\nWord: slow\\nAntonym: fast\\n\\nWord: bad\\nAntonym: good\\n\\nWord: poor\\nAntonym: rich\\n\\nWord: old\\nAntonym: new\\n\\nWord: unintelligent\\nAntonym: intelligent\\n\\nWord: difficult\\nAntonym: easy\\n\\nWord: unfair\\nAntonym: fair\\n\\nWord: rude\\nAntonym: polite\\n\\nWord: agitated\\nAntonym: calm\\n\\nWord: hate\\nAntonym: love\\n\\nWord: crooked\\nAntonym: straight\\n\\nWord: low\\nAntonym: high\\n\\nWord: quiet\\nAntonym: loud\\n\\nWord: wet\\nAntonym: dry\\n\\nWord: complex\\nAntonym: simple\\n\\nWord: stale\\nAntonym: fresh\\n\\nWord: wrong\\nAntonym: right\\n\\nWord: disobedient\\nAntonym: ob'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
